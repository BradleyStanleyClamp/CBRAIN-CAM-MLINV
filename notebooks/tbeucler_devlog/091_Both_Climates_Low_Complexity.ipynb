{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tb - 6/25/2022 - Testing the hypothesis that low-complexity models are more descriptive when phrased using climate-invariant inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfspool-0/home/tbeucler/CBRAIN-CAM/notebooks/tbeucler_devlog\n"
     ]
    }
   ],
   "source": [
    "from cbrain.climate_invariant import *\n",
    "from cbrain.climate_invariant_utils import *\n",
    "import pickle\n",
    "#import h5netcdf\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cbrain.imports import *\n",
    "from cbrain.utils import *\n",
    "from cbrain.normalization import *\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[1], True)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[2], True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/SPCAM_PHYS/'\n",
    "path_array = {}\n",
    "climate_str = ['cold','hot','both']\n",
    "set_str = ['train','valid','test']\n",
    "test_clim_str = ['cold','hot','both','medium']\n",
    "\n",
    "path_array['cold'] = [path_data+'2021_03_18_O3_TRAIN_M4K_shuffle.nc',\n",
    "                      path_data+'2021_03_18_O3_VALID_M4K.nc',\n",
    "                      path_data+'2021_03_18_O3_TEST_M4K.nc']\n",
    "path_array['hot'] = [path_data+'2021_03_18_O3_TRAIN_P4K_shuffle.nc',\n",
    "                     path_data+'2021_03_18_O3_VALID_P4K.nc',\n",
    "                     path_data+'2021_03_18_O3_TEST_P4K.nc']\n",
    "path_array['both'] = [path_data+'2022_04_18_TRAIN_M4K_P4K_shuffle.nc',\n",
    "                      path_data+'2022_04_18_VALID_M4K_P4K.nc',\n",
    "                      path_data+'2022_04_18_TEST_M4K_P4K.nc']\n",
    "path_array['medium'] = [path_data+'2021_01_24_O3_TRAIN_shuffle.nc',\n",
    "                        path_data+'2021_01_24_O3_VALID.nc',\n",
    "                        path_data+'2021_01_24_O3_TEST.nc']\n",
    "\n",
    "path_input_norm = path_data + '2021_01_24_NORM_O3_small.nc'\n",
    "scale_dict = pickle.load(open(path_data+'009_Wm2_scaling.pkl','rb'))\n",
    "path_norm_RH = path_data + '2021_02_01_NORM_O3_RH_small.nc'\n",
    "scale_dict_RH = scale_dict.copy()\n",
    "scale_dict_RH['RH'] = 0.01*L_S/G, # Arbitrary 0.1 factor as specific humidity is generally below 2%\n",
    "path_train_RH = path_data + '2021_01_24_O3_small_shuffle.nc'\n",
    "path_norm_BMSE = path_data + '2021_06_16_NORM_BMSE_small.nc'\n",
    "path_train_BMSE = path_data + '2021_06_16_BMSE_small_shuffle.nc'\n",
    "path_norm_LHF_nsDELQ = path_data + '2021_02_01_NORM_O3_LHF_nsDELQ_small.nc'\n",
    "path_train_LHF_nsDELQ = path_data + '2021_02_01_O3_LHF_nsQ_small_shuffle.nc'\n",
    "\n",
    "in_vars = ['QBP','TBP','PS','SOLIN','SHFLX','LHFLX'] # We take the large-scale climate state as inputs\n",
    "out_vars = ['PHQ','TPHYSTND','QRL','QRS'] # and we output the response of clouds/storms to these climate conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz = 12\n",
    "lw = 2\n",
    "siz = 100\n",
    "\n",
    "plt.rc('text', usetex=False)\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rc('font', family='serif', size=fz)\n",
    "mpl.rcParams['lines.linewidth'] = lw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen_rescaling(input_rescaling,path_norm,path_train,scale_dict):\n",
    "    return DataGeneratorCI(\n",
    "        data_fn = path_train,\n",
    "        input_vars = input_rescaling,\n",
    "        output_vars = out_vars,\n",
    "        norm_fn = path_norm,\n",
    "        input_transform = ('mean', 'maxrs'),\n",
    "        output_transform = scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_RH = train_gen_rescaling(['RH','TBP','PS', 'SOLIN', 'SHFLX', 'LHFLX'],\n",
    "                                   path_norm_RH,path_train_RH,scale_dict_RH)\n",
    "train_gen_BMSE = train_gen_rescaling(['QBP','BMSE','PS', 'SOLIN', 'SHFLX', 'LHFLX'],\n",
    "                                     path_norm_BMSE,path_train_BMSE,scale_dict)\n",
    "train_gen_LHF_nsDELQ = train_gen_rescaling(['QBP','TBP','PS', 'SOLIN', 'SHFLX', 'LHF_nsDELQ'],\n",
    "                                           path_norm_LHF_nsDELQ,path_train_LHF_nsDELQ,scale_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator_singleDS(path,rescaling=None):\n",
    "    \n",
    "    in_vars = ['QBP','TBP','PS','SOLIN','SHFLX','LHFLX'] # We take the large-scale climate state as inputs\n",
    "    out_vars = ['PHQ','TPHYSTND','QRL','QRS'] # and we output the response of clouds/storms to these climate conditions\n",
    "    path_input_norm = path_data + '2021_01_24_NORM_O3_small.nc'\n",
    "    scale_dict = pickle.load(open(path_data+'009_Wm2_scaling.pkl','rb'))\n",
    "    \n",
    "    if rescaling=='CI':\n",
    "        gen = DataGeneratorCI(\n",
    "        data_fn = path,\n",
    "        input_vars = in_vars,\n",
    "        output_vars = out_vars,\n",
    "        norm_fn = path_input_norm,\n",
    "        batch_size=8192,\n",
    "        input_transform = ('mean', 'maxrs'),\n",
    "        output_transform = scale_dict,\n",
    "        Qscaling = 'RH',\n",
    "        Tscaling = 'BMSE',\n",
    "        LHFscaling = 'LHF_nsDELQ',\n",
    "        hyam=hyam, hybm=hybm, # Arrays to define mid-levels of hybrid vertical coordinate\n",
    "        inp_sub_Qscaling=train_gen_RH.input_transform.sub, # What to subtract from RH inputs\n",
    "        inp_div_Qscaling=train_gen_RH.input_transform.div, # What to divide RH inputs by\n",
    "        inp_sub_Tscaling=train_gen_BMSE.input_transform.sub,\n",
    "        inp_div_Tscaling=train_gen_BMSE.input_transform.div,\n",
    "        inp_sub_LHFscaling=train_gen_LHF_nsDELQ.input_transform.sub,\n",
    "        inp_div_LHFscaling=train_gen_LHF_nsDELQ.input_transform.div\n",
    "        ) \n",
    "    else:\n",
    "        gen = DataGeneratorCI(\n",
    "        data_fn = path,\n",
    "        input_vars = in_vars,\n",
    "        output_vars = out_vars,\n",
    "        norm_fn = path_input_norm,\n",
    "        batch_size=8192,\n",
    "        input_transform = ('mean', 'maxrs'),\n",
    "        output_transform = scale_dict\n",
    "        )\n",
    "\n",
    "    return gen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFgen = {}\n",
    "CIgen = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate =  cold\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n",
      "Climate =  hot\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n",
      "Climate =  both\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n",
      "Climate =  medium\n",
      "Set =  train\n",
      "Set =  valid\n",
      "Set =  test\n"
     ]
    }
   ],
   "source": [
    "for iclimate,clim in enumerate(test_clim_str):\n",
    "    print('Climate = ',clim)\n",
    "    BFgen[clim] = {}\n",
    "    CIgen[clim] = {}\n",
    "    \n",
    "    for iset,st in enumerate(set_str):\n",
    "        print('Set = ',st)\n",
    "        \n",
    "        BFgen[clim][st] = Generator_singleDS(path_array[clim][iset])\n",
    "        CIgen[clim][st] = Generator_singleDS(path_array[clim][iset],rescaling='CI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:    \n",
    "- Train on training set containing both climates    \n",
    "- Evaluate on test set of each climate separately   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(64,)) ## input after rh and tns transformation\n",
    "dense_out = Dense(120, activation='linear')(inp)\n",
    "MLR_BF = tf.keras.models.Model(inp, dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = Input(shape=(64,)) ## input after rh and tns transformation\n",
    "dense2 = Dense(120, activation='linear')(inp2)\n",
    "MLR_CI = tf.keras.models.Model(inp2, dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               7800      \n",
      "=================================================================\n",
      "Total params: 7,800\n",
      "Trainable params: 7,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MLR_BF.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_BF.compile(tf.keras.optimizers.Adam(), loss=mse)\n",
    "MLR_CI.compile(tf.keras.optimizers.Adam(), loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HDF5 = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/HDF5_DATA/'\n",
    "save_name = '2022_07_12_MLR_both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save_BF = ModelCheckpoint(path_HDF5+save_name+'_BF.hdf5',save_best_only=True, monitor='val_loss', mode='min')\n",
    "mcp_save_CI = ModelCheckpoint(path_HDF5+save_name+'_CI.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nep = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLR_BF.fit_generator(BFgen['both']['train'], epochs=Nep, validation_data=BFgen['both']['valid'],\n",
    "#                      callbacks=[earlyStopping, mcp_save_BF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_BF.load_weights(path_HDF5+'2022_06_25_MLR_both'+'_BF.hdf5')\n",
    "MLR_CI.load_weights(path_HDF5+save_name+'_CI.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11518/11518 [==============================] - 4028s 350ms/step - loss: 522.6601 - val_loss: 500.0511\n",
      "Epoch 2/20\n",
      "11518/11518 [==============================] - 3337s 290ms/step - loss: 493.4946 - val_loss: 490.3513\n",
      "Epoch 3/20\n",
      "11518/11518 [==============================] - 3461s 301ms/step - loss: 487.5516 - val_loss: 486.5635\n",
      "Epoch 4/20\n",
      "11518/11518 [==============================] - 3482s 302ms/step - loss: 484.5118 - val_loss: 484.2162\n",
      "Epoch 5/20\n",
      "11518/11518 [==============================] - 3437s 298ms/step - loss: 482.4926 - val_loss: 482.5940\n",
      "Epoch 6/20\n",
      "11518/11518 [==============================] - 3468s 301ms/step - loss: 481.0623 - val_loss: 481.4206\n",
      "Epoch 7/20\n",
      "11518/11518 [==============================] - 4668s 405ms/step - loss: 479.9922 - val_loss: 480.5183\n",
      "Epoch 8/20\n",
      "11518/11518 [==============================] - 3886s 337ms/step - loss: 479.1516 - val_loss: 479.7866\n",
      "Epoch 9/20\n",
      "11518/11518 [==============================] - 3566s 310ms/step - loss: 478.4668 - val_loss: 479.1901\n",
      "Epoch 10/20\n",
      "11518/11518 [==============================] - 3586s 311ms/step - loss: 477.8957 - val_loss: 478.6811\n",
      "Epoch 11/20\n",
      "11518/11518 [==============================] - 3455s 300ms/step - loss: 477.4092 - val_loss: 478.2450\n",
      "Epoch 12/20\n",
      "11518/11518 [==============================] - 3451s 300ms/step - loss: 476.9902 - val_loss: 477.8694\n",
      "Epoch 13/20\n",
      "11518/11518 [==============================] - 3376s 293ms/step - loss: 476.6249 - val_loss: 477.5402\n",
      "Epoch 14/20\n",
      "11518/11518 [==============================] - 3405s 296ms/step - loss: 476.3033 - val_loss: 477.2489\n",
      "Epoch 15/20\n",
      "11518/11518 [==============================] - 3481s 302ms/step - loss: 476.0193 - val_loss: 476.9920\n",
      "Epoch 16/20\n",
      "11518/11518 [==============================] - 3486s 303ms/step - loss: 475.7658 - val_loss: 476.7634\n",
      "Epoch 17/20\n",
      "11518/11518 [==============================] - 3437s 298ms/step - loss: 475.5387 - val_loss: 476.5583\n",
      "Epoch 18/20\n",
      "11518/11518 [==============================] - 3428s 298ms/step - loss: 475.3347 - val_loss: 476.3685\n",
      "Epoch 19/20\n",
      "11518/11518 [==============================] - 3385s 294ms/step - loss: 475.1501 - val_loss: 476.2076\n",
      "Epoch 20/20\n",
      "11518/11518 [==============================] - 3462s 301ms/step - loss: 474.9828 - val_loss: 476.0553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbc9024af98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLR_CI.fit_generator(CIgen['both']['train'], epochs=Nep, validation_data=CIgen['both']['valid'],\n",
    "#                      callbacks=[earlyStopping, mcp_save_CI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 'test'\n",
    "BFtest = {}; CItest = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate =  cold\n",
      "295.88531876196726\n",
      "BF  None\n",
      "298.2587363408428\n",
      "CI  None\n",
      "Climate =  hot\n",
      "633.5436136481907\n",
      "BF  None\n",
      "644.8244153655563\n",
      "CI  None\n",
      "Climate =  both\n",
      "464.71446620507896\n",
      "BF  None\n",
      "471.54157585319956\n",
      "CI  None\n",
      "Climate =  medium\n",
      "432.73554985118056\n",
      "BF  None\n",
      "438.2393532639788\n",
      "CI  None\n"
     ]
    }
   ],
   "source": [
    "for iclimate,clim in enumerate(test_clim_str):\n",
    "    print('Climate = ',clim)\n",
    "    BFg = BFgen[clim][st]; CIg = CIgen[clim][st]\n",
    "    BFtest[clim] = MLR_BF.evaluate_generator(BFg)\n",
    "    print('BF ',print(BFtest[clim]))\n",
    "    CItest[clim] = MLR_CI.evaluate_generator(CIg)\n",
    "    print('CI ',print(CItest[clim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = path_data + 'PKL_DATA/2022_07_12_Performance_Four_Climates_MLR_Both'\n",
    "\n",
    "pickle.dump({'BFtest':BFtest,'CItest':CItest},open(path_test,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cold': 295.88531876196726, 'hot': 633.5436136481907, 'both': 464.71446620507896, 'medium': 432.73554985118056}\n",
      "{'cold': 298.2587363408428, 'hot': 644.8244153655563, 'both': 471.54157585319956, 'medium': 438.2393532639788}\n"
     ]
    }
   ],
   "source": [
    "print(BFtest); print(CItest);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tb - 06/26/2022 - The results are negative once again. If allowed to be fully non-local and use data from both climates, climate-invariant mappings are no better than brute-force ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tb - 07/12/2022 - Trying again with improved CI data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tb - 07/13/2022 - Results are still negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(inp,N_layer):\n",
    "    if N_layer>0:\n",
    "        densout = Dense(128, activation='linear')(inp)\n",
    "        densout = LeakyReLU(alpha=0.3)(densout)\n",
    "    else: dense_out = Dense(120, activation='linear')(inp)\n",
    "    for i in range (N_layer-1):\n",
    "        densout = Dense(128, activation='linear')(densout)\n",
    "        densout = LeakyReLU(alpha=0.3)(densout)\n",
    "    if N_layer>0: dense_out = Dense(120, activation='linear')(densout)\n",
    "    return tf.keras.models.Model(inp, dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpBF = Input(shape=(64,)) ## input after rh and tns transformation\n",
    "NN_BF = NN_model(inpBF,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpCI = Input(shape=(64,)) ## input after rh and tns transformation\n",
    "NN_CI = NN_model(inpCI,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 120)               15480     \n",
      "=================================================================\n",
      "Total params: 122,872\n",
      "Trainable params: 122,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_BF.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_BF.compile(tf.keras.optimizers.Adam(), loss=mse)\n",
    "NN_CI.compile(tf.keras.optimizers.Adam(), loss=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_HDF5 = '/DFS-L/DATA/pritchard/tbeucler/SPCAM/HDF5_DATA/'\n",
    "save_name = '2022_07_20_NN_both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save_BF = ModelCheckpoint(path_HDF5+save_name+'_BF.hdf5',save_best_only=True, monitor='val_loss', mode='min')\n",
    "mcp_save_CI = ModelCheckpoint(path_HDF5+save_name+'_CI.hdf5',save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nep = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11518/11518 [==============================] - 1889s 164ms/step - loss: 334.9878 - val_loss: 313.1066\n",
      "Epoch 2/20\n",
      "11518/11518 [==============================] - 1721s 149ms/step - loss: 304.9694 - val_loss: 305.9150\n",
      "Epoch 3/20\n",
      "11518/11518 [==============================] - 1388s 120ms/step - loss: 295.1630 - val_loss: 293.6352\n",
      "Epoch 4/20\n",
      "11518/11518 [==============================] - 1424s 124ms/step - loss: 289.1955 - val_loss: 287.0230\n",
      "Epoch 5/20\n",
      "11518/11518 [==============================] - 1365s 118ms/step - loss: 285.0640 - val_loss: 279.1640\n",
      "Epoch 6/20\n",
      "11518/11518 [==============================] - 1422s 123ms/step - loss: 282.6011 - val_loss: 282.7758\n",
      "Epoch 7/20\n",
      "11518/11518 [==============================] - 1364s 118ms/step - loss: 279.8889 - val_loss: 276.7263\n",
      "Epoch 8/20\n",
      "11518/11518 [==============================] - 1415s 123ms/step - loss: 278.2617 - val_loss: 280.8800\n",
      "Epoch 9/20\n",
      "11518/11518 [==============================] - 1379s 120ms/step - loss: 276.2747 - val_loss: 290.4882\n",
      "Epoch 10/20\n",
      "11518/11518 [==============================] - 1328s 115ms/step - loss: 275.5694 - val_loss: 278.1130\n",
      "Epoch 11/20\n",
      "11518/11518 [==============================] - 1395s 121ms/step - loss: 274.1175 - val_loss: 276.4712\n",
      "Epoch 12/20\n",
      "11518/11518 [==============================] - 1533s 133ms/step - loss: 273.1561 - val_loss: 270.3209\n",
      "Epoch 13/20\n",
      "11518/11518 [==============================] - 1370s 119ms/step - loss: 272.5018 - val_loss: 270.0210\n",
      "Epoch 14/20\n",
      "11518/11518 [==============================] - 1359s 118ms/step - loss: 271.7794 - val_loss: 270.8004\n",
      "Epoch 15/20\n",
      "11518/11518 [==============================] - 1357s 118ms/step - loss: 271.5086 - val_loss: 269.2721\n",
      "Epoch 16/20\n",
      "11518/11518 [==============================] - 1383s 120ms/step - loss: 270.8427 - val_loss: 271.9500\n",
      "Epoch 17/20\n",
      "11518/11518 [==============================] - 1402s 122ms/step - loss: 270.3893 - val_loss: 267.5793\n",
      "Epoch 18/20\n",
      "11518/11518 [==============================] - 1403s 122ms/step - loss: 269.7807 - val_loss: 268.5929\n",
      "Epoch 19/20\n",
      "11518/11518 [==============================] - 1386s 120ms/step - loss: 269.6749 - val_loss: 269.1249\n",
      "Epoch 20/20\n",
      "11518/11518 [==============================] - 1400s 122ms/step - loss: 269.0194 - val_loss: 269.3032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f25c0060128>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NN_BF.fit_generator(BFgen['both']['train'], epochs=Nep, validation_data=BFgen['both']['valid'],\n",
    "#                      callbacks=[earlyStopping, mcp_save_BF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_BF.load_weights(path_HDF5+save_name+'_BF.hdf5')\n",
    "NN_CI.load_weights(path_HDF5+save_name+'_CI.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11518/11518 [==============================] - 3737s 324ms/step - loss: 311.3695 - val_loss: 292.6528\n",
      "Epoch 2/20\n",
      "11518/11518 [==============================] - 3767s 327ms/step - loss: 284.8158 - val_loss: 279.4147\n",
      "Epoch 3/20\n",
      "11518/11518 [==============================] - 3954s 343ms/step - loss: 276.9533 - val_loss: 273.3161\n",
      "Epoch 4/20\n",
      "11518/11518 [==============================] - 3745s 325ms/step - loss: 272.8733 - val_loss: 270.2524\n",
      "Epoch 5/20\n",
      "11518/11518 [==============================] - 3620s 314ms/step - loss: 270.0789 - val_loss: 268.9627\n",
      "Epoch 6/20\n",
      "11518/11518 [==============================] - 3869s 336ms/step - loss: 268.3501 - val_loss: 267.4414\n",
      "Epoch 7/20\n",
      "11518/11518 [==============================] - 3587s 311ms/step - loss: 266.9269 - val_loss: 266.6688\n",
      "Epoch 8/20\n",
      "11518/11518 [==============================] - 3505s 304ms/step - loss: 265.9302 - val_loss: 265.9037\n",
      "Epoch 9/20\n",
      "11518/11518 [==============================] - 3624s 315ms/step - loss: 264.9980 - val_loss: 265.7380\n",
      "Epoch 10/20\n",
      "11518/11518 [==============================] - 3638s 316ms/step - loss: 264.2003 - val_loss: 263.5823\n",
      "Epoch 11/20\n",
      "11518/11518 [==============================] - 3620s 314ms/step - loss: 263.5299 - val_loss: 263.0397\n",
      "Epoch 12/20\n",
      "11518/11518 [==============================] - 3862s 335ms/step - loss: 262.9500 - val_loss: 262.1046\n",
      "Epoch 13/20\n",
      "11518/11518 [==============================] - 3863s 335ms/step - loss: 262.4888 - val_loss: 264.1135\n",
      "Epoch 14/20\n",
      " 4048/11518 [=========>....................] - ETA: 22:10 - loss: 263.0258"
     ]
    }
   ],
   "source": [
    "# NN_CI.fit_generator(CIgen['both']['train'], epochs=Nep, validation_data=CIgen['both']['valid'],\n",
    "#                      callbacks=[earlyStopping, mcp_save_CI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 'test'\n",
    "BFtest = {}; CItest = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate =  cold\n",
      "174.17758354362925\n",
      "BF  None\n",
      "169.099352453999\n",
      "CI  None\n",
      "Climate =  hot\n",
      "357.1082640298506\n",
      "BF  None\n",
      "349.40386396321753\n",
      "CI  None\n",
      "Climate =  both\n",
      "265.6429237867399\n",
      "BF  None\n",
      "259.2516082086083\n",
      "CI  None\n",
      "Climate =  medium\n",
      "253.7495367765223\n",
      "BF  None\n",
      "245.02913522304988\n",
      "CI  None\n"
     ]
    }
   ],
   "source": [
    "for iclimate,clim in enumerate(test_clim_str):\n",
    "    print('Climate = ',clim)\n",
    "    BFg = BFgen[clim][st]; CIg = CIgen[clim][st]\n",
    "    BFtest[clim] = NN_BF.evaluate_generator(BFg)\n",
    "    print('BF ',print(BFtest[clim]))\n",
    "    CItest[clim] = NN_CI.evaluate_generator(CIg)\n",
    "    print('CI ',print(CItest[clim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = path_data + 'PKL_DATA/2022_07_22_Performance_Four_Climates_NN_Both.pkl'\n",
    "\n",
    "pickle.dump({'BFtest':BFtest,'CItest':CItest},open(path_test,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cold': 174.17758354362925, 'hot': 357.1082640298506, 'both': 265.6429237867399, 'medium': 253.7495367765223}\n",
      "{'cold': 169.099352453999, 'hot': 349.40386396321753, 'both': 259.2516082086083, 'medium': 245.02913522304988}\n"
     ]
    }
   ],
   "source": [
    "print(BFtest); print(CItest);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
